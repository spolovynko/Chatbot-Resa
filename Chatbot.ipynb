{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38207355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0721e64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ten CARDINAL\n",
      "five CARDINAL\n",
      "evening TIME\n"
     ]
    }
   ],
   "source": [
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "raw_text = 'I would like to book a table for ten people  five at the evening'\n",
    "sent = NER(raw_text)\n",
    "\n",
    "for word in sent.ents:\n",
    "    print(word.text,word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ace1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "would AUX\n",
      "like VERB\n",
      "to PART\n",
      "book VERB\n",
      "a DET\n",
      "table NOUN\n",
      "for ADP\n",
      "ten NUM\n",
      "people NOUN\n",
      "  SPACE\n",
      "friday PROPN\n",
      "at ADP\n",
      "9 NUM\n",
      "pm NOUN\n"
     ]
    }
   ],
   "source": [
    "for chunk in sent:\n",
    "    print(chunk, chunk.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d00d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "a table\n",
      "ten people\n",
      "9 pm\n"
     ]
    }
   ],
   "source": [
    "for chunk in sent.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57feefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8f5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"intent.json\",\"r\") as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbce8c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dico = []\n",
    "corpus = []\n",
    "data = []\n",
    "tags = []\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = NER(text)\n",
    "    tokens = [token.lemma_ for token in tokens if token.lemma_.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    tag = intent[('tag')]\n",
    "    dico += tokenizer(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        tags.append(tag)\n",
    "        pattern_tokens = tokenizer(pattern)\n",
    "        dico += pattern_tokens\n",
    "        data.append([pattern_tokens, tag])\n",
    "        corpus.append(' '.join(pattern_tokens))\n",
    "    for resp in intent['responses']:\n",
    "        dico += tokenizer(resp)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b3a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "dico_tags = {tag : i for (i, tag) in enumerate(set(tags))}\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "y_train = [dico_tags[tag] for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef72250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train.toarray())\n",
    "        self.x_data = X_train.toarray()\n",
    "        self.y_data = np.array(y_train)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "batch_size = 8\n",
    "\n",
    "    \n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa35105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_size = 8\n",
    "output_size = len(set(tags))\n",
    "input_size = len(X_train.toarray()[0])\n",
    "learning_rate = 0.001\n",
    "n_epochs=300\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(input_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out =self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(x)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35ceb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50/300, loss: 0.9496\n",
      "epoch: 100/300, loss: 0.5372\n",
      "epoch: 150/300, loss: 0.3842\n",
      "epoch: 200/300, loss: 0.1293\n",
      "epoch: 250/300, loss: 0.0474\n",
      "epoch: 300/300, loss: 0.0972\n",
      "final loss, loss: 0.0972\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for (words,labels) in train_loader:\n",
    "        words = words.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        \n",
    "        outputs = model(words).float()\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"epoch: {epoch+1}/{n_epochs}, loss: {loss.item():.4f}\")\n",
    "print(f\"final loss, loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4494374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of people'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_sentence = 'I would like to book a table for tomorow evening'\n",
    "\n",
    "vect_sent = vectorizer.transform([' '.join(tokenizer(test_sentence))]).toarray()\n",
    "output = model(torch.tensor(vect_sent).to(device).float())\n",
    "list(dico_tags.keys())[torch.softmax(output, dim=1).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db61bc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booking',\n",
       " 'datetime',\n",
       " 'funny',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'number of people',\n",
       " 'payments',\n",
       " 'thanks'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f58e01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want to book a table this morning',\n",
       " 'I want a table this morning',\n",
       " 'I want to book a table for lunch',\n",
       " 'I want a table for lunch',\n",
       " 'I want to book a table this evening',\n",
       " 'I want a table this evening',\n",
       " 'I want to book a table tomorow evening',\n",
       " 'I want a table tomorow evening',\n",
       " 'I would like to book a table this morning',\n",
       " 'I would like a table this morning',\n",
       " 'I would like to book a table for lunch',\n",
       " 'I would like a table for lunch',\n",
       " 'I would like to book a table this evening',\n",
       " 'I would like a table this evening',\n",
       " 'I would like to book a table tomorow evening',\n",
       " 'I would like a table tomorow evening',\n",
       " 'I wish to book a table this morning',\n",
       " 'I wish a table this morning',\n",
       " 'I wish to book a table for lunch',\n",
       " 'I wish a table for lunch',\n",
       " 'I wish to book a table this evening',\n",
       " 'I wish a table this evening',\n",
       " 'I wish to book a table tomorow evening',\n",
       " 'I wish a table tomorow evening']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = ['want', 'would like', 'wish']\n",
    "complements = ['to book a table', 'a table']\n",
    "times = ['this morning', 'for lunch', 'for this evening', 'for tomorow evening']\n",
    "\n",
    "bookings = [f\"I {verb} {complement} {time}\" for verb in verbs for time in times for complement in complements]\n",
    "bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b639e27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 75), ('Hi', 45), ('like', 29), ('9', 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "listing = ['Hello', 'Hi', '9', 'like']\n",
    "process.extract('Hlo', listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a225197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want today want tomorrow\n"
     ]
    }
   ],
   "source": [
    "tokens = NER(\"I don't want today I want tomorrow\")\n",
    "\n",
    "print(' '.join(token.lemma_ for token in tokens if not token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af46134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python385jvsc74a57bd09977e029b2da6177bb9bc7be3b4cc732c21fce726b7c7753acdf2f8f3db06ed7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
